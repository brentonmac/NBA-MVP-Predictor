{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IQGrXb1Vlyej"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "quQh09LZoiZI",
    "outputId": "11573a44-1624-461a-eacb-98d50fec7d59"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "# test\n",
    "#uploaded = files.upload() #per 36 minutes, per 100 poss, player award shares, player per game, player totals, advanced, all star selections, end of season teams (voting), team summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "poqiXtBkoxgN",
    "outputId": "c5932178-a061-46f6-be4d-0ae3ce351851"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Per 100 Poss.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m file_path \u001b[38;5;241m=\u001b[39m file\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Store the DataFrame in the dictionary with the file name as the key\u001b[39;00m\n\u001b[0;32m     20\u001b[0m dataframes[file] \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Per 100 Poss.csv'"
     ]
    }
   ],
   "source": [
    "#cite chat gpt later\n",
    "csv_files = [\n",
    "    'Per 100 Poss.csv', 'Per 36 Minutes.csv', 'Player Award Shares.csv',\n",
    "    'Player Per Game.csv',\n",
    "    'Player Totals.csv','Advanced.csv', 'All-Star Selections.csv', 'End of Season Teams (Voting).csv',\n",
    "]\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Read each CSV file and store it in the dictionary\n",
    "for file in csv_files:\n",
    "    # Construct the full file path assuming the CSV files are in the current working directory\n",
    "    file_path = file\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Store the DataFrame in the dictionary with the file name as the key\n",
    "    dataframes[file] = df\n",
    "\n",
    "# Now you can access each DataFrame using its file name as the key\n",
    "# For example, to access the 'Per 100 Poss.csv' DataFrame:\n",
    "per_100_poss_df = dataframes['Per 100 Poss.csv']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "dataframes['Advanced.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "K_UFrFHWy-6K",
    "outputId": "c4b2ef03-331b-4676-908b-986a829577f4"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Per 100 Poss.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m csv_files: \u001b[38;5;66;03m#This double for loop filters all of our data to only seasons past the year 2000\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      3\u001b[0m     dataframes[i] \u001b[38;5;241m=\u001b[39m dataframes[i][dataframes[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m]\n\u001b[0;32m      4\u001b[0m dataframes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlayer Award Shares.csv\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Per 100 Poss.csv'"
     ]
    }
   ],
   "source": [
    "for i in csv_files: #This double for loop filters all of our data to only seasons past the year 2000\n",
    "  for row in dataframes[i]:\n",
    "    dataframes[i] = dataframes[i][dataframes[i]['season'] >= 2000]\n",
    "dataframes['Player Award Shares.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SyZiE1XV_so"
   },
   "outputs": [],
   "source": [
    "#This cell filters the player award shares dataframe to only display the players associated with the mvp award (we don't care about the other awards)\n",
    "a = dataframes['Player Award Shares.csv'][(dataframes['Player Award Shares.csv']['award'] == 'nba mvp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdbKsw1Dqo50",
    "outputId": "bbbaaf3f-c81e-41a3-b86c-62efa44ffa55"
   },
   "outputs": [],
   "source": [
    "\"\"\"This is a large cell that does all of our merges. Some of the merges are outer and some are inner because the outer merges\n",
    "created too many unneccesary columns and duplicate player rows\"\"\"\n",
    "merged_df = dataframes['All-Star Selections.csv']\n",
    "merged_df = merged_df.merge(a, how='outer', on = ['player', 'season'])\n",
    "merged_df['made_asg'] = True\n",
    "merged_df['winner'] = merged_df['winner'].fillna(False)\n",
    "merged_df = merged_df.fillna(0)\n",
    "merged_df = merged_df.merge(dataframes['Advanced.csv'], how='outer', on = ['player', 'season', 'seas_id'])\n",
    "merged_df['made_asg'] = merged_df['made_asg'].fillna(False)\n",
    "merged_df['winner'] = merged_df['winner'].fillna(False) #merged_df was used to experiment on different decision trees\n",
    "merged_df = merged_df.fillna(0)\n",
    "merged_df3 = merged_df.merge(dataframes['Player Per Game.csv'], how = 'inner', on = ['player', 'season', 'seas_id']) #merged_df3 is used for the random forest and stats tests\n",
    "merged_df3 = merged_df3.merge(dataframes['Per 100 Poss.csv'], how = 'inner', on = ['player', 'season', 'seas_id'])\n",
    "merged_df3 = merged_df3.merge(dataframes['Per 36 Minutes.csv'], how = 'inner', on = ['player', 'season', 'seas_id'])\n",
    "merged_df3 = merged_df3.merge(dataframes['Player Totals.csv'], how = 'inner', on = ['player', 'season', 'seas_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "8P8PRZWmEKbq",
    "outputId": "0ecaf21a-1056-4248-e7ad-0fc7a1aa9bc0"
   },
   "outputs": [],
   "source": [
    "merged_df3 #Note that whenever a player was not mentioned in NBA MVP voting, they had 0s in the MVP columns because of .fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "ZyZrCbfTWwQN",
    "outputId": "cf5e4ae2-cc4f-4303-dd92-b9996513206d"
   },
   "outputs": [],
   "source": [
    "merged_df2 = pd.merge(dataframes['End of Season Teams (Voting).csv'], a, on='seas_id', how='inner')\n",
    "merged_df2 #used for first decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-_vdU-jY7zD"
   },
   "outputs": [],
   "source": [
    "y = [int(x) for x in merged_df2['winner']] #beginning the train/test split, first identifying X and y\n",
    "X = merged_df2.select_dtypes(include= ['float', 'int']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHHp56MPbwWt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Decision Tree\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X,y, random_state = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4Lzne_kcFss",
    "outputId": "78f96e9b-60c7-4666-d83c-4789465e2d4e"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\", random_state=110)\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "I1oyJOIlcKJp",
    "outputId": "257172e2-6b67-4568-fffe-535bd6ec1572"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "tree.plot_tree(dtree) #this ddecision tree is implying that all our past mvps have gotten at least 51 votes in first team all NBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIpfDO6te3pj",
    "outputId": "ef72cf91-f1fa-4b5c-9c6c-7b5e98e34c2f"
   },
   "outputs": [],
   "source": [
    "X.iloc[:,12] #Evidence that index 12 = first team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kahkjc2EwpSH"
   },
   "source": [
    "This next Decision Tree that we created differs from the other one because it is ran on data from merged_df, which includes much more data from other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlodb5oyzsOF",
    "outputId": "53b5b751-0f09-43d2-f2e5-c517697fc09e"
   },
   "outputs": [],
   "source": [
    "merged_df['made_asg'] = [int(x) for x in merged_df['made_asg']]\n",
    "y2 = [int(x) for x in merged_df['winner']]\n",
    "X2 = merged_df.select_dtypes(include= ['float', 'int']).fillna(0)\n",
    "X2 = X2.drop(columns = ['pts_max', 'share', 'season', 'seas_id', 'player_id_x', 'player_id_y', 'first', 'pts_won'])\n",
    "X2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cqAI5hI0UEf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Decision tree 2\n",
    "X2_train, X2_test, y2_train, y2_test = \\\n",
    "train_test_split(X2,y2, random_state = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JeuVQg_H0xey",
    "outputId": "7be69420-d6df-4808-9e7a-0175cc2bcfe3"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\", random_state=110)\n",
    "dtree.fit(X2_train, y2_train)\n",
    "dtree.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jg0xcN1V04U9",
    "outputId": "f2855339-e7cd-4a9c-bfb7-06e4d09e2fb5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "tree.plot_tree(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWnVFLDh3gFD",
    "outputId": "7c44ca9f-d3fd-4c65-ec00-4332f9388341"
   },
   "outputs": [],
   "source": [
    "X2.iloc[:,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Oc6ym4Z_1nv"
   },
   "outputs": [],
   "source": [
    "merged_df3['made_asg'] = [int(x) for x in merged_df3['made_asg']] # creating X3 and y3 for the random forest\n",
    "y3 = [int(x) for x in merged_df3['winner']]\n",
    "X3 = merged_df3.select_dtypes(include= ['float', 'int']).fillna(0)\n",
    "X3 = X3.drop(columns = ['pts_won', 'pts_max', 'share', 'season', 'seas_id', 'player_id_x', 'player_id_y', 'age_x', 'first', 'experience', 'ws_48' ])\n",
    "#everything after these stats above are to help make it more accurate. keep the ones above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-DWapb6X3ZmP",
    "outputId": "3b9f85f1-ba6f-4e8c-bc40-d9872a91dee5"
   },
   "outputs": [],
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEMCA-TSAhDa",
    "outputId": "0093a416-4095-411c-c76f-06d78e0ddca7"
   },
   "outputs": [],
   "source": [
    "X3drop = X3.filter(like = '_y').columns #filtering out duplicated data and/or irrelevant data\n",
    "X3 = X3.drop(columns = X3drop)\n",
    "for a in X3.columns:\n",
    "  print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmFCwS81ChHE"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoL6qK6PGWAl"
   },
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = \\\n",
    "train_test_split(X3,y3, random_state = 110)#random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9zyU1IEGdNM",
    "outputId": "928729c9-2c5b-435c-d0ae-e687497b6ca3"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=200, bootstrap = False)\n",
    "random_forest.fit(X3_train, y3_train)\n",
    "random_forest.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_cMKyaZGivh"
   },
   "outputs": [],
   "source": [
    "importances = random_forest.feature_importances_ #importances or significance of each data is stored here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9p9PDXPHUWV"
   },
   "outputs": [],
   "source": [
    "importances_dict = {} # puts an index that corresponds to merged_df3 column in a dictionary with the importances\n",
    "for i in range(len(importances)):\n",
    "  importances_dict[i] = importances[i]\n",
    "importances_dict\n",
    "sorted_importances = sorted(importances_dict.items(), key=lambda x: x[1], reverse=True) #chat gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2qjBiNqHqgy",
    "outputId": "e9b4ce96-8424-41c7-dd3a-5a332bb2c48b"
   },
   "outputs": [],
   "source": [
    "stats = [] #This cell adds the index of the merged_df3 column to each importance stat so it's easy to see\n",
    "num = 0\n",
    "for i in X3.columns:\n",
    "  stats.append(i + ' / ' + str(num))\n",
    "  num +=1\n",
    "stats_per_importance = {}\n",
    "for i in range(len(stats)):\n",
    "  stats_per_importance[stats[i]] = importances[i]\n",
    "stats_per_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_YEZUsmIdpx",
    "outputId": "7af5df9a-df39-4c38-a0d2-37e9aa8aa469"
   },
   "outputs": [],
   "source": [
    "sorted_stats = dict(sorted(stats_per_importance.items(), key=lambda item: item[1], reverse = True)) #This cell sorts the previous dictionary by highest value\n",
    "sorted_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t2Me48BKVNj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILixIsaP430C"
   },
   "outputs": [],
   "source": [
    "def scale_column(column): #making a function to use .apply on, got from chat gpt\n",
    "    max_value = column.max() #This cell scales the X3 dataframe to make the random forest more accurate\n",
    "    scaled_column = column / max_value\n",
    "    return scaled_column\n",
    "\n",
    "scaled_X3 = X3.apply(scale_column, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8RJjuyO9ZE3",
    "outputId": "d825fa28-fa38-4b49-b793-a2a404247579"
   },
   "outputs": [],
   "source": [
    "X4_train, X4_test, y4_train, y4_test = \\\n",
    "train_test_split(scaled_X3,y3, random_state = 110)#4th train/test split - this one is for the scaled random forest\n",
    "\n",
    "random_forest2 = RandomForestClassifier(n_estimators=300, bootstrap = True)\n",
    "random_forest2.fit(X4_train, y4_train)\n",
    "random_forest2.score(X4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1ibwTfi90U3"
   },
   "outputs": [],
   "source": [
    "importances2 = random_forest2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTiLIcN28VQD"
   },
   "outputs": [],
   "source": [
    "importances_dict2 = {} #doing the same as we did above with the importances dictionary where there is an index and the column name as well so it is readable\n",
    "for i in range(len(importances)):\n",
    "  importances_dict2[i] = importances2[i]\n",
    "importances_dict2\n",
    "sorted_importances2 = sorted(importances_dict2.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgLmPCbo-GpP"
   },
   "outputs": [],
   "source": [
    "stats2 = []\n",
    "num2 = 0\n",
    "for i in scaled_X3.columns:\n",
    "  stats2.append(i + ' / ' + str(num2))\n",
    "  num2 +=1\n",
    "stats_per_importance2 = {}\n",
    "for i in range(len(stats2)):\n",
    "  stats_per_importance2[stats2[i]] = importances2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1WaMsEaI3U3",
    "outputId": "39a4fa8e-c7a9-4b91-ee76-a57f3fb8a246"
   },
   "outputs": [],
   "source": [
    "sorted_stats2 = dict(sorted(stats_per_importance2.items(), key=lambda item: item[1], reverse = True))\n",
    "sorted_stats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFuKfKr1gMEQ"
   },
   "outputs": [],
   "source": [
    "def calculate_sum_of_products(row, array): #This function helps us calculate each players' individual 'mvp scores'\n",
    "    return np.sum(np.array(row) * np.array(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HSKAD2BaOm0"
   },
   "outputs": [],
   "source": [
    "mvp_scores = [] #creates the mvp scores list\n",
    "for i in range(len(X3)):\n",
    "  a = calculate_sum_of_products(X3.iloc[i,:], importances2)\n",
    "  mvp_scores.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDIMcGOWRH3P"
   },
   "outputs": [],
   "source": [
    "final_df = merged_df3 #makes a new column in the merged_df3 that is mvp scores\n",
    "final_df['mvp_scores'] = mvp_scores\n",
    "seasons = np.arange(2000,2024,1)\n",
    "df_by_season = {} #This is gonna gelp show the highest mvp score in each year\n",
    "for i in seasons:\n",
    "  a = merged_df3[merged_df3['season'] == i]\n",
    "  df_by_season[i] = a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-M-Yut4WbL9K"
   },
   "outputs": [],
   "source": [
    "predicted_mvp_per_year = [] #finds the name of the person with the highest mvp score for each year starting at 2000\n",
    "for i in seasons:\n",
    "  max_index = df_by_season[i]['mvp_scores'].idxmax()\n",
    "  row = df_by_season[i].loc[max_index]\n",
    "  predicted_mvp_per_year.append(row['player'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzAa-9IReFT7",
    "outputId": "c0343b46-0be1-459e-828d-6eca72f40ade"
   },
   "outputs": [],
   "source": [
    "predicted_mvp_per_year #our predicted mvps from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2zk3rvpeoQT"
   },
   "outputs": [],
   "source": [
    "real_mvps_pre = dataframes['Player Award Shares.csv'][dataframes['Player Award Shares.csv']['award'] == 'nba mvp']\n",
    "mvp_names = [] #This cell displats the real mvp results, will use to see the accuracy of our test\n",
    "\n",
    "for index, row in real_mvps_pre.iterrows():\n",
    "    if row['winner']:\n",
    "        mvp_names.append(row['player'])\n",
    "mvp_names.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_G57liGaVrH7",
    "outputId": "3f66cf11-eb2e-49e9-eff9-2de52a6fe523"
   },
   "outputs": [],
   "source": [
    "mvp_names #The real mvps (our predictions are quite different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yRf8cice7lc",
    "outputId": "c80fb6ee-5f4c-4fb5-fe65-bce28e6f3b7e"
   },
   "outputs": [],
   "source": [
    "percent_accuracy = 0 #Testing how many we got right/wrong\n",
    "t_or_f_accuracy = []\n",
    "for i in range(len(mvp_names)):\n",
    "  if mvp_names[i] == predicted_mvp_per_year[i]:\n",
    "    percent_accuracy += 1\n",
    "    t_or_f_accuracy.append(True)\n",
    "  else:\n",
    "    t_or_f_accuracy.append(False)\n",
    "t_and_f = [percent_accuracy, 23 - percent_accuracy]\n",
    "t_and_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yesb9vgUj5uW",
    "outputId": "66ba9511-5584-4ec7-ff3e-e0307269d009"
   },
   "outputs": [],
   "source": [
    "t_or_f_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih66eG6pfpDK",
    "outputId": "7e9bdb6b-3382-4481-b393-ee18139bfba1"
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "true_list = [True for i in range(23)] #This cell is doing a t-test between the average rates of True mvp predictions from our model and the real model (which is 100% true)\n",
    "z_stat, p_value = scipy.stats.ttest_ind(t_or_f_accuracy, true_list)\n",
    "p_value #This p-value means that we reject the null that our model aligns with the real model, and our model is not 100% accurate. (obviously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvVs8mjbioau"
   },
   "outputs": [],
   "source": [
    "corr_df = merged_df3.corr(numeric_only = True) #This is finding the correlation between each statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "cAZB4Urx05bt",
    "outputId": "1439ed37-e64f-4f9a-d356-343f9f633f1e"
   },
   "outputs": [],
   "source": [
    "corr_df[['share']].sort_values(by='share', ascending=False).head(10) #showing the 10 highest correlations with the MVP voting share\n",
    "#Note that many of these stata are the ones we deleted for the random forests and therefore are irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "Pl0k4BOSc2-R",
    "outputId": "cf981372-7914-4d56-bef0-fdba25fcab6d"
   },
   "outputs": [],
   "source": [
    "corr_df[['share']].sort_values(by='share', ascending=False).iloc[8:18] #The highest correlations within normal stats and share which is the share of the mvp voting pool are also the stats that were voted most important by the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WXk3NDV1TXd"
   },
   "source": [
    "**Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IT862DhThq_g",
    "outputId": "97acfe4e-1aa8-4565-ca7b-4f47db6e32b7"
   },
   "outputs": [],
   "source": [
    "#Make the Data usable for the graphs\n",
    "csv_files1 = ['Player Award Shares.csv', 'Team Summaries.csv']\n",
    "dataframes1 = {}\n",
    "for file in csv_files1:\n",
    "    file_path1 = file\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    dataframes1[file] = df1\n",
    "dataframes1['Player Award Shares.csv'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "AjuVw7ihhs1r",
    "outputId": "a6339169-01eb-43b4-cd33-eb5b11e6034c"
   },
   "outputs": [],
   "source": [
    "Graph2 = dataframes1['Player Award Shares.csv']\n",
    "for i in csv_files1:\n",
    "  for row in dataframes1[i]:\n",
    "    dataframes1[i] = dataframes1[i][dataframes1[i]['season'] >= 1977] #first year of ABA and NBA merger so let's use this data only\n",
    "for i in csv_files1:\n",
    "  for row in dataframes1[i]:\n",
    "    dataframes1[i] = dataframes1[i][dataframes1[i]['season'] >= 1977]\n",
    "Graph2 = Graph2[~Graph2['award'].str.contains('smoy|dpoy|mip|nba roy')] #we're only analyzing nba mvps so we delete all other data that are not nba mvps\n",
    "Graph2 = Graph2[~(Graph2['winner']==False)] #again we only want mvp winners so we delete all other data\n",
    "Graph2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "UjeEDxp8hvYl",
    "outputId": "12990b73-9729-4ffb-d00c-4d7fc3282306"
   },
   "outputs": [],
   "source": [
    "#using data from url: https://hoop-social.com/nba-team-market-size-rankings/ we add another column to our data to include market size alogn with the teams\n",
    "def merge_column(row):\n",
    "  if 'ATL'in row['tm'] or 'BRK'in row['tm'] or 'BOS' in row['tm'] or 'CHI' in row['tm'] or 'DAL' in row['tm'] or 'GSW' in row['tm'] or 'HOU' in row['tm'] or 'LAC' in row['tm'] or 'LAL' in row['tm'] or 'NYK' in row['tm'] or 'PHI' in row['tm'] or 'PHO' in row['tm'] or 'TOR' in row['tm'] or 'WAS' in row['tm']:\n",
    "    return 'Large'\n",
    "  elif 'CLE'in row['tm'] or 'DEN'in row['tm'] or 'DET' in row['tm'] or 'MIA' in row['tm'] or 'MIN' in row['tm'] or 'ORL' in row['tm']:\n",
    "    return 'Medium'\n",
    "  elif 'IND'in row['tm'] or 'MEM'in row['tm'] or 'MIL' in row['tm'] or 'NOP' in row['tm'] or 'OKC' in row['tm'] or 'POR' in row['tm'] or 'SAC' in row['tm'] or 'SAS' in row['tm'] or 'UTA' in row['tm']:\n",
    "    return 'Small'\n",
    "Graph2['market size'] = Graph2.apply(merge_column, axis=1) #merge function to make it one table\n",
    "Graph2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "p64yxemVhx1d",
    "outputId": "656d2d00-ca46-4e35-f901-b640efc40b35"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "market_counts = Graph2['market size'].value_counts() #this variable is our frequency (number of times) large, medium, small appear in the column\n",
    "labels = ['Large', 'Medium', 'Small']\n",
    "colors = [ 'firebrick', 'cadetblue', 'linen']\n",
    "#graph details and features\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "bars = ax.bar(labels, market_counts, color = colors)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_tick_params(pad=5)\n",
    "ax.yaxis.set_tick_params(pad=10)\n",
    "plt.xlabel(\"Market Size\")\n",
    "plt.ylabel(\"Number of MVPs\")\n",
    "bar_color = bars[0].get_facecolor()\n",
    "for bar in bars:\n",
    "  ax.text(\n",
    "      bar.get_x() + bar.get_width() / 2,\n",
    "      bar.get_height() + 0.3,\n",
    "      round(bar.get_height(), 1),\n",
    "      horizontalalignment='center',\n",
    "      weight='bold'\n",
    "  )\n",
    "ax.set_title('Number of MVP Players from Market Size',\n",
    "             loc='Center', )\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True, color='#EEEEEE')\n",
    "ax.xaxis.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hNaAGW-h2Xq"
   },
   "outputs": [],
   "source": [
    "for i in csv_files1:\n",
    "  for row in dataframes1[i]:\n",
    "    dataframes1[i] = dataframes1[i][dataframes1[i]['season'] >= 1976] #first year of ABA and NBA merger is 1977 so we start our data from there\n",
    "#this function will take a year after 1976 as an input and display a graph of the wins that each team got in the regular season with a highlighted bar of the MVP's team\n",
    "def Team_Wins_In_Season (year):\n",
    "  from matplotlib import pyplot as plt\n",
    "  Graph3 = dataframes1['Team Summaries.csv']\n",
    "  bad_str = ['League Average']\n",
    "  Graph3 = Graph3[~Graph3['team'].isin(bad_str)] #We dont want to include the League Average rows so we remove them from the dataset\n",
    "  Seasonstats = Graph3.loc[(Graph3['season'] == year)] #with the input variable we only extract the data from that season\n",
    "  mvp_tm = Graph2.loc[(Graph2['season'] == year), 'tm'].values[0] #returns string of team abbreviation of the MVP for that year\n",
    "  mvp_team = Seasonstats.loc[(Graph3['abbreviation'] == mvp_tm), 'team'].values[0] #in order to connect the mvp_tm variable with Seasonstats we set them equal to each other using the abbreviation column in Seasonstats\n",
    "  wins_tm = Seasonstats[['team', 'w']] #returns Dataframe with teams and number of wins\n",
    "  #graph features and detaisl\n",
    "  fig, ax = plt.subplots(figsize=(16, 9))\n",
    "  colors = ['red' if category == mvp_tm else 'gray' for category in Seasonstats['abbreviation']] #highlights the team where the MVP is from\n",
    "  ax.barh(Seasonstats['abbreviation'], Seasonstats['w'], color=colors)\n",
    "  ax.xaxis.set_ticks_position('none')\n",
    "  ax.yaxis.set_ticks_position('none')\n",
    "  ax.xaxis.set_tick_params(pad=5)\n",
    "  ax.yaxis.set_tick_params(pad=10)\n",
    "  ax.invert_yaxis()\n",
    "  for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.2, i.get_y()+0.5,\n",
    "            str(round((i.get_width()), 2)), fontsize=10, fontweight='bold', color='black')\n",
    "  ax.set_title(\"Team Wins in \" + str(year) + \" with the MVP from: \" + mvp_team + \" (\" + mvp_tm + \")\",\n",
    "             loc='center', fontsize=18)\n",
    "  plt.show()\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "dRkxcLhXh47y",
    "outputId": "43e2afc5-5dd3-41f9-b530-75be8ac2d0a3"
   },
   "outputs": [],
   "source": [
    "Team_Wins_In_Season(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "tQvr2THOfSMp",
    "outputId": "bebade99-9d83-4057-d11c-98230c5bc9fa"
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=merged_df3, x=\"pts\", y=\"mvp_scores\", hue=\"winner\", size = 'winner', sizes = (200,10))\n",
    "plt.title(\"The Relationship Between Points and MVP Score\", fontsize=16)\n",
    "#The graph shows the relationship between total pts scored over the season and our mvp_scores, as well as enlarging the true MVP winners\n",
    "#Note the true MVP winners have higher mvp scores for the most part, and they also score a lot of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "7EJpMTRO05pH",
    "outputId": "4b2cf470-6243-4e46-ffe9-4792876647ae"
   },
   "outputs": [],
   "source": [
    "ppg = pd.read_csv('Player Per Game.csv')\n",
    "ast = pd.read_csv('All-Star Selections.csv')\n",
    "\n",
    "#per 36 minutes, per 100 poss, player award shares, player per game, player totals, advanced, all star selections, end of season teams (voting)\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "## take both csv files and merge them. Then create a histogram which has the points per game of every nba player. After that\n",
    "#take the all star names and change the color of the bars containing all stars\n",
    "\n",
    "\n",
    "\n",
    "# extract the necessary data and dmerge\n",
    "ppg_2020 = ppg[ppg['season']== 2020]\n",
    "points = ppg_2020['pts_per_game']\n",
    "all_stars_2020 = ast[ast['season']==2020]\n",
    "\n",
    "\n",
    "result = ppg_2020[['player', 'pts_per_game']]\n",
    "#create the histogram\n",
    "bins = [ 0, 5, 10, 15, 20, 25, 30, 35]\n",
    "hist_values, bins, _ = plt.hist(result['pts_per_game'], bins = bins, edgecolor = 'black', color = 'lavender')\n",
    "\n",
    "\n",
    "ast_p =ast[ast['season'] == 2020]['player']\n",
    "ast_i = result.index[result['player'].isin(ast_p)].tolist()\n",
    "#Loop whuch implements the colors\n",
    "for i,start in  enumerate(bins[:-1]):\n",
    "  end =  bins[i+1]\n",
    "  ast_in_bin = result[(result['pts_per_game']>= start) & (result['pts_per_game'] < end)]['player'].isin(ast_p)\n",
    "  ast_i_in_bin = ast_in_bin.index[ast_in_bin].tolist()\n",
    "  for j in ast_i_in_bin:\n",
    "     plt.bar(bins[i], hist_values[i], width=bins[i + 1] - bins[i], align='edge', color='lightcoral', edgecolor='black') #This coral hightlights if there is an all star in that category\n",
    "\n",
    "#draws the histogram\n",
    "for i, txt in enumerate(hist_values):\n",
    "  plt.annotate(int(txt), (bins[i], hist_values[i]), ha = 'center', va = 'bottom')\n",
    "plt.xlabel(\"Points Per Game\")\n",
    "plt.ylabel(\"Number Of Players\")\n",
    "plt.title('The Distribution of ppg of NBA players from 2020')\n",
    "\n",
    "plt.xticks(bins[:-1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "W4-BvF53sjH0",
    "outputId": "1a8e31cd-b90e-435e-826b-8a98bac7278c"
   },
   "outputs": [],
   "source": [
    "data = final_df[['mvp_scores']] #This is a histogram that shows the dsitribution of our computed mvp_scores\n",
    "sns.histplot(data, kde=False, color='skyblue', bins=30)\n",
    "plt.xlim(0)\n",
    "plt.title('Distribution of mvp_scores of players from 2000-2023')\n",
    "plt.xlabel('mvp_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_km2Sxvso3o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
